{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "157ad9c6",
   "metadata": {},
   "source": [
    "# About:\n",
    "\n",
    "This code does not contain data visualizations, the reasoning behind the imputation methods used, sampling technique, feature enginering, metrics choice and the choice of model. This document creates a pipeline of operations. The arguments behind the each of the operations mentioned above are detailed in the document named documentation.pdf. \n",
    "\n",
    "In this document there are four functions i.e., treating missing values, label encoding, feature transformation and model building. Then the pipeline is created based on these functions. Finally, the predictions are made on the test data and are stored in the excel file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb91cf6",
   "metadata": {},
   "source": [
    "Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1515e9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2cadcf",
   "metadata": {},
   "source": [
    "Create a function to treat missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4320fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def treat_missing_values(data):\n",
    "    # Keeping only those columns that are required\n",
    "    columns_to_keep = ['custAge', 'profession', 'marital', 'schooling', 'default', 'housing',\n",
    "                       'loan', 'contact', 'month', 'day_of_week', 'campaign', 'pdays', 'previous',\n",
    "                       'poutcome', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx',\n",
    "                       'euribor3m', 'nr.employed', 'pmonths', 'pastEmail', 'responded']\n",
    "    \n",
    "    data = data[columns_to_keep]\n",
    "\n",
    "    # Feature engineering for schooling\n",
    "    schooling_category = {\n",
    "        'basic.4y' : 'basic',\n",
    "        'basic.6y' : 'basic',\n",
    "        'basic.9y' : 'basic',\n",
    "        'high.school': 'high.school',\n",
    "        'illiterate':'illiterate',\n",
    "        'professional.course': 'professional.course',\n",
    "        'university.degree':'university.degree',\n",
    "        'unknown':'unknown',\n",
    "    }\n",
    "\n",
    "    data.loc[:,'schooling'] = data['schooling'].replace(schooling_category)\n",
    "\n",
    "    # Imputation of missing values in education based on profession\n",
    "    imputation_mapping = {\n",
    "        'blue-collar' : 'basic',\n",
    "        'self-employed': 'illiterate',\n",
    "        'technician'   : 'professional.course',\n",
    "        'admin.'        : 'university.degree',\n",
    "        'services'      : 'high.school',\n",
    "        'management'    : 'university.degree',\n",
    "        'retired'       : 'unknown',\n",
    "        'entrepreneur'  : 'university.degree'\n",
    "    }\n",
    "\n",
    "    data.loc[:,'schooling'] = data['schooling'].combine_first(data['profession'].map(imputation_mapping))\n",
    "\n",
    "    # Profession & treating missing values of age\n",
    "    data.loc[:, 'employment_status'] = data['profession'].apply(lambda x: 'retired' if x == 'retired' else ('student' if x == 'student' else 'working'))\n",
    "\n",
    "    # Imputing age values\n",
    "    mean_age_retired = data.loc[data['employment_status'] == 'retired', 'custAge'].mean()\n",
    "    mean_age_student = data.loc[data['employment_status'] == 'student', 'custAge'].mean()\n",
    "    median_age_working = data.loc[data['employment_status'] == 'working', 'custAge'].median()\n",
    "\n",
    "    data.loc[:,'custAge'] = np.where((data['employment_status'] == 'retired') & data['custAge'].isna(), mean_age_retired, data['custAge'])\n",
    "    data.loc[:,'custAge'] = np.where((data['employment_status'] == 'student') & data['custAge'].isna(), mean_age_student, data['custAge'])\n",
    "    data.loc[:,'custAge'] = np.where((data['employment_status'] == 'working') & data['custAge'].isna(), median_age_working, data['custAge'])\n",
    "\n",
    "    # Impute random day for missing 'day_of_week' values\n",
    "    data.loc[:,'day_of_week'] = data['day_of_week'].apply(lambda day: np.random.choice(['mon', 'tue', 'wed', 'thu', 'fri']) if pd.isna(day) else day)\n",
    "\n",
    "    # Drop remaining missing values\n",
    "    data = data.dropna()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afd26ef",
   "metadata": {},
   "source": [
    "Create a function to label encode the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd2e8fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(data):\n",
    "    # Label encoding for 'profession'\n",
    "    data.loc[:,'profession'] = data['profession'].map({'student': 'Dependents', 'retired': 'Dependents', 'unemployed': 'Unemployed&Unknown', 'unknown': 'Unemployed&Unknown',\n",
    "                                                 'admin.': 'Working', 'blue-collar': 'Working', 'entrepreneur': 'Working', 'housemaid': 'Working',\n",
    "                                                 'management': 'Working', 'self-employed': 'Working', 'services': 'Working', 'technician': 'Working'})\n",
    "\n",
    "    # Label encoding for 'marital'\n",
    "    data.loc[:,'marital'] = data['marital'].map({'single': 'Single&Divorced', 'divorced': 'Single&Divorced', 'married': 'married', 'unknown': 'Unknown'})\n",
    "\n",
    "    # Label encoding for 'schooling'\n",
    "    data.loc[:,'schooling'] = data['schooling'].map({'basic': 'Uneducated&BasicEducation', 'high.school': 'Uneducated&BasicEducation',\n",
    "                                               'illiterate': 'Uneducated&BasicEducation', 'unknown': 'Unknown',\n",
    "                                               'professional.course': 'Educated', 'university.degree': 'Educated'})\n",
    "\n",
    "    # Label encoding for 'default'\n",
    "    data.loc[:,'default'] = data['default'].map({'no': 'No', 'unknown': 'Yes&Unknown', 'yes': 'Yes&Unknown'})\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original data\n",
    "    data_copy_c = data.copy()\n",
    "\n",
    "    # Define a mapping for specific months\n",
    "    quarter_mapping = {'dec': 'QuarterEnd', 'sep': 'QuarterEnd', 'jun': 'QuarterEnd', 'mar': 'QuarterEnd'}\n",
    "\n",
    "    # Replace specified months with 'QuarterEnd' in the copied DataFrame\n",
    "    data_copy_c['month_mapped'] = data_copy_c['month'].replace(quarter_mapping)\n",
    "\n",
    "    # Replace other months with 'others' in the copied DataFrame\n",
    "    data_copy_c['month_mapped'].replace(to_replace=data_copy_c['month_mapped'][~data_copy_c['month_mapped'].isin(['QuarterEnd'])].unique(), value='others', inplace=True)\n",
    "\n",
    "    data.loc[:,'month'] = data_copy_c['month_mapped']\n",
    "\n",
    "    # Label encoding for 'day_of_week'\n",
    "    data.loc[:,'day_of_week'] = data['day_of_week'].map({'mon': 'WeekBeginning', 'tue': 'WeekBeginning', 'wed': 'WeekBeginning',\n",
    "                                                   'thu': 'WeekEnding', 'fri': 'WeekEnding'})\n",
    "\n",
    "    # Feature engineering of other variables\n",
    "    # pdays\n",
    "    conditions = [\n",
    "        (data['pdays'] == 999),\n",
    "        (data['pdays'] < 5),\n",
    "        ((data['pdays'] >= 5) & (data['pdays'] <= 10)),\n",
    "        (data['pdays'] > 10)\n",
    "    ]\n",
    "\n",
    "    choices = ['first visit', 'less than 5 days', '5 to 10 days', 'greater than 10 days']\n",
    "\n",
    "    # Create the 'pduration' column based on conditions\n",
    "    data.loc[:,'pduration'] = np.select(conditions, choices, default='unknown')\n",
    "\n",
    "    # pmonths\n",
    "    conditions = [\n",
    "        (data['pmonths'] == 999),\n",
    "        (data['pmonths'] <= 0.2),\n",
    "        (data['pmonths'] > 0.2)\n",
    "    ]\n",
    "\n",
    "    choices = ['first visit', 'less than 2 months', 'greater than 2 months']\n",
    "\n",
    "    # Create the 'pduration' column based on conditions\n",
    "    data['pduration_m'] = np.select(conditions, choices, default='unknown')\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeec2f5",
   "metadata": {},
   "source": [
    "Create a function for feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "332962fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "def feature_transformation(data):\n",
    "    # Drop target and unnecessary columns\n",
    "    X = data.drop(['responded', 'pdays', 'pmonths', 'employment_status'], axis=1)\n",
    "    y = data['responded']\n",
    "\n",
    "    # One-hot encode categorical columns\n",
    "    X_encoded = pd.get_dummies(X, columns=['loan', 'marital', 'schooling', 'default', 'housing', 'day_of_week',\n",
    "                                           'poutcome', 'pduration', 'pduration_m', 'profession', 'month', 'contact'], drop_first=True)\n",
    "\n",
    "    # Identify continuous columns for normalization\n",
    "    continuous_columns = ['custAge', 'campaign', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx',\n",
    "                           'euribor3m', 'nr.employed', 'pastEmail']\n",
    "\n",
    "    # Extract the continuous columns from X_encoded\n",
    "    X_continuous = X_encoded[continuous_columns]\n",
    "\n",
    "    # Instantiate StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit and transform the scaler on the continuous data\n",
    "    X_continuous_normalized = scaler.fit_transform(X_continuous)\n",
    "\n",
    "    # Replace the original continuous columns in X_encoded with the normalized ones\n",
    "    X_encoded[continuous_columns] = X_continuous_normalized\n",
    "\n",
    "    return X_encoded, y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2732e502",
   "metadata": {},
   "source": [
    "Create a function for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b85ccc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def train_propensify_model(X_encoded, y):\n",
    "    # Set a random seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Apply SMOTEENN to the training data\n",
    "    smoteenn = SMOTEENN(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smoteenn.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Create a Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Create a Support Vector Machine (SVM) classifier with tuned parameters\n",
    "    svm_classifier = SVC(kernel='rbf', C=1.0, gamma='scale', probability=True, random_state=42)\n",
    "\n",
    "    # Ensemble the classifiers using a VotingClassifier\n",
    "    ensemble_classifier = VotingClassifier(estimators=[\n",
    "        ('rf', rf_classifier),\n",
    "        ('svm', svm_classifier)\n",
    "    ], voting='hard')  # 'hard' for probability voting\n",
    "\n",
    "    # Fit the ensemble model on the resampled training data\n",
    "    ensemble_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Save the trained ensemble_classifier if needed\n",
    "    # joblib.dump(ensemble_classifier, 'ensemble_classifier.joblib')\n",
    "\n",
    "    return ensemble_classifier\n",
    "\n",
    "# Example usage:\n",
    "# trained_model = train_propensify_model(X_encoded, y)\n",
    "# joblib.dump(trained_model, 'propensify_model.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90cb753",
   "metadata": {},
   "source": [
    "Load training and testing dataset. Add a column (target variable) to test data to allow the above functions to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1e6d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_excel(r\"C:\\Users\\HARI CHARAN\\Downloads\\UPGRAD_ALL\\Upgrad\\train.xlsx\")\n",
    "test_data = pd.read_excel(r\"C:\\Users\\HARI CHARAN\\Downloads\\UPGRAD_ALL\\Upgrad\\test.xlsx\")\n",
    "test_data['responded'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa64c09",
   "metadata": {},
   "source": [
    "Define the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5239aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HARI CHARAN\\AppData\\Local\\Temp\\ipykernel_10184\\1573980397.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'employment_status'] = data['profession'].apply(lambda x: 'retired' if x == 'retired' else ('student' if x == 'student' else 'working'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['propensify_model.joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    " \n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('missing_values', FunctionTransformer(func=treat_missing_values)),\n",
    "    ('label_encoding', FunctionTransformer(func=label_encoding)),\n",
    "    ('feature_transformation', FunctionTransformer(func=feature_transformation)),\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "X_train_transformed, y_train = preprocessing_pipeline.fit_transform(train_data)\n",
    "\n",
    "# Train model using the transformed data\n",
    "trained_model = train_propensify_model(X_train_transformed, y_train)\n",
    "\n",
    "# Save the preprocessing pipeline\n",
    "joblib.dump(preprocessing_pipeline, 'preprocessing_pipeline.joblib')\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(trained_model, 'propensify_model.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d44a459",
   "metadata": {},
   "source": [
    "Load the trained model and preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2b87708",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded_model = joblib.load('propensify_model.joblib')\n",
    "\n",
    "preprocessing_pipeline = joblib.load('preprocessing_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4585abfa",
   "metadata": {},
   "source": [
    "Perform the pipeline tramsformations on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8c4f82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed, _ = preprocessing_pipeline.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a938b4b",
   "metadata": {},
   "source": [
    "Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fcce5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = loaded_model.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab3b550a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        custAge  campaign  previous  emp.var.rate  cons.price.idx  \\\n",
      "0     -0.188221 -0.207980  1.713222     -0.763555        1.076265   \n",
      "1     -0.507809 -0.207980  1.713222     -2.231472       -2.077163   \n",
      "2      1.090129 -0.565991  1.713222     -1.210312       -1.186580   \n",
      "3     -1.040455 -0.565991 -0.347067      0.832007       -0.231888   \n",
      "4     -0.081692 -0.565991 -0.347067     -0.125330       -0.654655   \n",
      "...         ...       ...       ...           ...             ...   \n",
      "32945 -0.188221 -0.565991 -0.347067      0.640540        0.721071   \n",
      "32946 -0.827396  0.508043 -0.347067     -1.210312       -1.186580   \n",
      "32947 -0.827396 -0.207980 -0.347067     -1.210312       -1.186580   \n",
      "32948 -0.827396 -0.565991 -0.347067      0.832007        1.537150   \n",
      "32949 -1.573101 -0.207980 -0.347067     -1.912359       -1.065294   \n",
      "\n",
      "       cons.conf.idx  euribor3m  nr.employed  pastEmail  loan_unknown  ...  \\\n",
      "0           0.650961  -1.593395    -2.849255   1.354201         False  ...   \n",
      "1           2.321153  -1.650120    -2.097493   1.354201         False  ...   \n",
      "2          -1.236139  -1.338134    -0.959390   1.354201         False  ...   \n",
      "3           0.954632   0.767049     0.839818  -0.274884         False  ...   \n",
      "4          -0.325125   0.297622     0.389319  -0.274884         False  ...   \n",
      "...              ...        ...          ...        ...           ...  ...   \n",
      "32945       0.889560   0.705114     0.322371  -0.274884         False  ...   \n",
      "32946      -1.236139  -1.373442    -0.959390  -0.274884         False  ...   \n",
      "32947      -1.236139  -1.354341    -0.959390  -0.274884         False  ...   \n",
      "32948      -0.281744   0.764154     0.839818  -0.274884         False  ...   \n",
      "32949      -0.064836  -1.376915    -1.278784  -0.274884         False  ...   \n",
      "\n",
      "       pduration_first visit  pduration_greater than 10 days  \\\n",
      "0                       True                           False   \n",
      "1                      False                           False   \n",
      "2                       True                           False   \n",
      "3                       True                           False   \n",
      "4                       True                           False   \n",
      "...                      ...                             ...   \n",
      "32945                   True                           False   \n",
      "32946                   True                           False   \n",
      "32947                   True                           False   \n",
      "32948                   True                           False   \n",
      "32949                   True                           False   \n",
      "\n",
      "       pduration_less than 5 days  pduration_m_greater than 2 months  \\\n",
      "0                           False                              False   \n",
      "1                            True                              False   \n",
      "2                           False                              False   \n",
      "3                           False                              False   \n",
      "4                           False                              False   \n",
      "...                           ...                                ...   \n",
      "32945                       False                              False   \n",
      "32946                       False                              False   \n",
      "32947                       False                              False   \n",
      "32948                       False                              False   \n",
      "32949                       False                              False   \n",
      "\n",
      "       pduration_m_less than 2 months  profession_Unemployed&Unknown  \\\n",
      "0                               False                          False   \n",
      "1                                True                          False   \n",
      "2                               False                          False   \n",
      "3                               False                          False   \n",
      "4                               False                          False   \n",
      "...                               ...                            ...   \n",
      "32945                           False                          False   \n",
      "32946                           False                          False   \n",
      "32947                           False                          False   \n",
      "32948                           False                          False   \n",
      "32949                           False                          False   \n",
      "\n",
      "       profession_Working  month_others  contact_telephone  Predicted_Response  \n",
      "0                    True         False              False                 yes  \n",
      "1                    True         False              False                 yes  \n",
      "2                    True          True              False                 yes  \n",
      "3                    True          True              False                  no  \n",
      "4                    True          True              False                  no  \n",
      "...                   ...           ...                ...                 ...  \n",
      "32945                True          True               True                  no  \n",
      "32946                True          True              False                 yes  \n",
      "32947                True          True              False                 yes  \n",
      "32948                True         False               True                  no  \n",
      "32949                True         False               True                 yes  \n",
      "\n",
      "[32145 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Add a new column 'Predictions' to the preprocessed test data\n",
    "X_test_transformed['Predicted_Response'] = predictions\n",
    "\n",
    "# Print the DataFrame with all columns and predictions\n",
    "print(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0162dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted_Response\n",
       "no     23593\n",
       "yes     8552\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed['Predicted_Response'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12617010",
   "metadata": {},
   "source": [
    "Saving the resultant data to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ba3c8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file_path = 'test_with.predictions.xlsx'\n",
    "X_test_transformed.to_excel(excel_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ef8dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547a285a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
